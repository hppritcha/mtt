# INI file for Cori GPU nodes

[MTTDefaults]
scratchdir = master_scratch
description = OpenMPI master
platform = NERSC-cori-cgpu
executor = sequential
organization = LANL
#trial = True

[Profile:Installed]

#======================================================================
# Middleware construction phases - get the middleware, build, and
# install it. This isn't a required phase - if the purpose of this test
# is to simply stress the physical system, then one can skip this phase
#======================================================================

[MiddlewareGet:OMPIMaster]
plugin = OMPI_Snapshot
url =  https://download.open-mpi.org/nightly/open-mpi/master
version_file = /global/homes/h/hpp/mtt_cgpu/vf_master
mpi_name = ompi-nightly-master

#----------------------------------------------------------------------

[MiddlewareBuild:OMPIMaster]
parent = MiddlewareGet:OMPIMaster
plugin = Autotools
configure_options = --with-cray-xpmem=no --with-ofi=no --with-ucx=/usr/common/software/sles15_cgpu/ucx/1.10.0 --with-cuda=/usr/common/software/sles15_cgpu/cuda/11.1.1
make_options = -j 12
#checkpoint_file = /global/homes/h/hpp/mtt_cgpu/master_scratch/ompi_restart_file

#======================================================================
# Test construction phases - get and build the tests that the
# target software will run.
#======================================================================

[ASIS TestGet:OSU]
plugin = Copytree
src = /global/homes/h/hpp/osu-micro-benchmarks-5.7.1
#parent required or test will run even if build failed
parent = MiddlewareBuild:OMPIMaster


#======================================================================
# Test build phase
#======================================================================

[TestBuild:OSUInstalled]
parent = TestGet:OSU
merge_stdout_stderr = 1
stderr_save_lines = 100
middleware = MiddlewareBuild:OMPIMaster
#autogen_cmd = ./autogen.sh
configure_options = CC=mpicc CXX=mpic++ F77=mpif77 FC=mpifort --with-cuda=/usr/common/software/sles15_cgpu/cuda/11.1.1 --with-cuda-libpath=/usr/common/software/sles15_cgpu/cuda/11.1.1/lib64/compat --enable-cuda
make_options = -j 4
#checkpoint_file = /global/homes/h/hpp/mtt_cgpu/master_scratch/ompi_restart_file


#======================================================================
# Define some default launcher execution parameters
#======================================================================

[LauncherDefaults:OMPI]
plugin = OpenMPI
#plugin = ALPS
command = mpirun -v
np = 2

skipped = 77
merge_stdout_stderr = 1
stdout_save_lines = 1000
stderr_save_lines = 1000

#======================================================================
# Test run phase - the executor will automatically change directory to
# the top directory where the tests were installed, so any search for
# executables will take place relative to that point
#======================================================================

[TestRun:OSUInstalledOMPI]
#plugin = ALPS
plugin = OpenMPI
parent = TestBuild:OSUInstalled
timeout = 600
test_dir = "mpi/pt2pt"
#checkpoint_file = /global/homes/h/hpp/mtt_cgpu/master_scratch/ompi_restart_file
#test_dir = "communicator, datatype, environment, group, info, io, pt2pt, random, topology"
stdout_save_lines = 1000
stderr_save_lines = 1000


#======================================================================
# Reporter phase
#======================================================================

[Reporter: text file backup]
plugin = TextFile
filename = mttresults.txt
summary_footer =
detail_header  =
detail_footer  =
textwrap = 78

#----------------------------------------------------------------------

[Reporter: IU database]
plugin = IUDatabase
realm = OMPI
username = lanl
pwfile = /global/homes/h/hpp/mtt_cgpu/pw_file
platform = NERSC-cori
url = https://mtt.open-mpi.org/submit/cpy/api/

[Reporter: JunitXML]
plugin = JunitXML
filename = mttresults.xml
textwrap = 78
